{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from typing import Optional, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/gauravkhanal/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initialize sentiment analyzer once\n",
    "try:\n",
    "    nltk.data.find('vader_lexicon')\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRANSACTION_COST = 0.001  # 0.1% transaction cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"Fetch historical stock data from Yahoo Finance.\"\"\"\n",
    "    data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "    if data.empty:\n",
    "        raise ValueError(f\"No stock data found for ticker {ticker}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Preprocess text for sentiment analysis.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)      # Remove numbers\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_news(ticker: str, days: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"Generate synthetic news data for demonstration.\"\"\"\n",
    "    dates = pd.date_range(end=dt.datetime.now(), periods=days).tolist()\n",
    "    headlines = [\n",
    "        f\"{ticker} announces new product\",\n",
    "        f\"{ticker} beats earnings expectations\",\n",
    "        f\"{ticker} stock downgraded by analysts\",\n",
    "        f\"{ticker} expands into new markets\",\n",
    "        f\"{ticker} faces regulatory challenges\",\n",
    "        f\"{ticker} reports strong quarterly growth\",\n",
    "        f\"{ticker} CEO steps down\",\n",
    "        f\"{ticker} partners with major industry player\",\n",
    "        f\"{ticker} cuts revenue forecast\",\n",
    "        f\"{ticker} announces layoffs\"\n",
    "    ]\n",
    "    \n",
    "    news_data = []\n",
    "    for date in dates:\n",
    "        daily_headlines = np.random.choice(\n",
    "            headlines, \n",
    "            size=np.random.randint(0, 4), \n",
    "            replace=False\n",
    "        ).tolist()\n",
    "        \n",
    "        for headline in daily_headlines:\n",
    "            news_data.append({\n",
    "                'date': date.strftime('%Y-%m-%d'),\n",
    "                'headline': headline,\n",
    "                'clean_headline': clean_text(headline)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(news_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Analyze sentiment of news headlines.\"\"\"\n",
    "    sentiment_cols = ['compound_score', 'positive_score', 'negative_score', 'neutral_score']\n",
    "    \n",
    "    for col in sentiment_cols:\n",
    "        if col not in news_df.columns:\n",
    "            news_df[col] = np.nan\n",
    "            \n",
    "    for idx, row in news_df.iterrows():\n",
    "        scores = sia.polarity_scores(row['clean_headline'])\n",
    "        news_df.at[idx, 'compound_score'] = scores['compound']\n",
    "        news_df.at[idx, 'positive_score'] = scores['pos']\n",
    "        news_df.at[idx, 'negative_score'] = scores['neg']\n",
    "        news_df.at[idx, 'neutral_score'] = scores['neu']\n",
    "    \n",
    "    # Aggregate by date and add rolling average\n",
    "    sentiment_by_date = news_df.groupby('date').agg({\n",
    "        'compound_score': 'mean',\n",
    "        'positive_score': 'mean',\n",
    "        'negative_score': 'mean',\n",
    "        'neutral_score': 'mean',\n",
    "        'headline': 'count'\n",
    "    }).rename(columns={'headline': 'news_count'})\n",
    "    \n",
    "    sentiment_by_date['rolling_compound'] = (\n",
    "        sentiment_by_date['compound_score']\n",
    "        .rolling(window=3, min_periods=1)\n",
    "        .mean()\n",
    "    )\n",
    "    \n",
    "    return sentiment_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals(stock_df: pd.DataFrame, \n",
    "                    sentiment_df: pd.DataFrame,\n",
    "                    threshold: float = 0.2,\n",
    "                    use_rolling: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Generate trading signals by merging stock and sentiment data.\"\"\"\n",
    "    # Make copies of input DataFrames\n",
    "    stock_data = stock_df.copy()\n",
    "    sentiment_data = sentiment_df.copy()\n",
    "    \n",
    "    # Convert indices to datetime and ensure single-level index\n",
    "    stock_data.index = pd.to_datetime(stock_data.index)\n",
    "    sentiment_data.index = pd.to_datetime(sentiment_data.index)\n",
    "    \n",
    "    # If stock_data has MultiIndex, convert to single level\n",
    "    if isinstance(stock_data.index, pd.MultiIndex):\n",
    "        stock_data = stock_data.reset_index(level=1, drop=True)\n",
    "    \n",
    "    # If sentiment_data has MultiIndex, convert to single level\n",
    "    if isinstance(sentiment_data.index, pd.MultiIndex):\n",
    "        sentiment_data = sentiment_data.reset_index(level=1, drop=True)\n",
    "    \n",
    "    # Merge data using join (more robust for index merging)\n",
    "    merged = stock_data.join(sentiment_data, how='left')\n",
    "    \n",
    "    # Forward fill sentiment scores\n",
    "    sentiment_cols = ['compound_score', 'positive_score', \n",
    "                     'negative_score', 'neutral_score', 'rolling_compound']\n",
    "    merged[sentiment_cols] = merged[sentiment_cols].fillna(method='ffill')\n",
    "    \n",
    "    # Generate signals\n",
    "    sentiment_col = 'rolling_compound' if use_rolling else 'compound_score'\n",
    "    merged['signal'] = 0\n",
    "    merged.loc[merged[sentiment_col] > threshold, 'signal'] = 1\n",
    "    merged.loc[merged[sentiment_col] < -threshold, 'signal'] = -1\n",
    "    \n",
    "    # Calculate returns\n",
    "    merged['returns'] = merged['Adj Close'].pct_change()\n",
    "    merged['strategy_returns'] = (\n",
    "        merged['signal'].shift(1) * merged['returns'] - \n",
    "        abs(merged['signal'].diff()) * TRANSACTION_COST\n",
    "    )\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(signals_df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Calculate performance metrics from trading signals.\"\"\"\n",
    "    signals_df['cumulative_returns'] = (1 + signals_df['returns']).cumprod() - 1\n",
    "    signals_df['cumulative_strategy_returns'] = (\n",
    "        (1 + signals_df['strategy_returns'].fillna(0)).cumprod() - 1\n",
    "    )\n",
    "    \n",
    "    total_days = len(signals_df)\n",
    "    positive_returns = signals_df['strategy_returns'] > 0\n",
    "    negative_returns = signals_df['strategy_returns'] < 0\n",
    "    \n",
    "    annualized_return = (\n",
    "        (1 + signals_df['cumulative_strategy_returns'].iloc[-1]) ** \n",
    "        (365 / total_days) - 1\n",
    "        if total_days > 0 else 0\n",
    "    )\n",
    "    \n",
    "    downside_returns = signals_df.loc[negative_returns, 'strategy_returns']\n",
    "    sortino_ratio = (\n",
    "        annualized_return / (downside_returns.std() * np.sqrt(252))\n",
    "        if len(downside_returns) > 0 else 0\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'total_days': total_days,\n",
    "        'profitable_days': positive_returns.sum(),\n",
    "        'win_rate': positive_returns.mean(),\n",
    "        'annualized_return': annualized_return,\n",
    "        'cumulative_return': signals_df['cumulative_strategy_returns'].iloc[-1],\n",
    "        'buy_hold_return': signals_df['cumulative_returns'].iloc[-1],\n",
    "        'max_drawdown': (\n",
    "            signals_df['cumulative_strategy_returns'].cummax() - \n",
    "            signals_df['cumulative_strategy_returns']).max(),\n",
    "        'volatility': signals_df['strategy_returns'].std() * np.sqrt(252),\n",
    "        'sharpe_ratio': (\n",
    "            signals_df['strategy_returns'].mean() / \n",
    "            signals_df['strategy_returns'].std()) * np.sqrt(252) \n",
    "            if signals_df['strategy_returns'].std() > 0 else 0,\n",
    "        'sortino_ratio': sortino_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(ticker: str, signals_df: pd.DataFrame) -> plt.Figure:\n",
    "    \"\"\"Visualize trading signals and performance.\"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 18), \n",
    "                           gridspec_kw={'height_ratios': [3, 1, 2]})\n",
    "    \n",
    "    # Price and sentiment\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_title(f'{ticker} Price and Sentiment')\n",
    "    ax1.plot(signals_df.index, signals_df['Adj Close'], label='Price', color='blue')\n",
    "    ax1.set_ylabel('Price ($)', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    \n",
    "    ax1b = ax1.twinx()\n",
    "    scatter = ax1b.scatter(\n",
    "        signals_df.index, \n",
    "        signals_df['rolling_compound'],\n",
    "        c=signals_df['rolling_compound'], \n",
    "        cmap='RdYlGn', \n",
    "        alpha=0.6\n",
    "    )\n",
    "    ax1b.set_ylabel('Sentiment Score', color='green')\n",
    "    ax1b.tick_params(axis='y', labelcolor='green')\n",
    "    plt.colorbar(scatter, ax=ax1b).set_label('Sentiment Score')\n",
    "    \n",
    "    # Trading signals\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_title('Trading Signals')\n",
    "    ax2.plot(signals_df.index, signals_df['signal'], 'o-', markersize=4)\n",
    "    ax2.set_ylabel('Signal (1=Buy, -1=Sell)')\n",
    "    ax2.set_ylim([-1.5, 1.5])\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Performance\n",
    "    ax3 = axes[2]\n",
    "    ax3.set_title('Strategy Performance')\n",
    "    ax3.plot(signals_df.index, signals_df['cumulative_returns'], label='Buy & Hold')\n",
    "    ax3.plot(signals_df.index, signals_df['cumulative_strategy_returns'], label='Strategy')\n",
    "    ax3.set_ylabel('Cumulative Returns')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(ticker: str, \n",
    "                start_date: str, \n",
    "                end_date: str,\n",
    "                threshold: float = 0.2) -> Tuple[pd.DataFrame, Dict, plt.Figure]:\n",
    "    \"\"\"Complete analysis pipeline.\"\"\"\n",
    "    print(f\"Analyzing {ticker} from {start_date} to {end_date}\")\n",
    "    \n",
    "    # 1. Fetch data\n",
    "    stock_data = fetch_stock_data(ticker, start_date, end_date)\n",
    "    news_data = generate_synthetic_news(ticker)\n",
    "    \n",
    "    # 2. Analyze sentiment\n",
    "    sentiment_scores = analyze_sentiment(news_data)\n",
    "    \n",
    "    # 3. Generate signals\n",
    "    signals_df = generate_signals(stock_data, sentiment_scores, threshold)\n",
    "    \n",
    "    # 4. Backtest\n",
    "    metrics = backtest_strategy(signals_df)\n",
    "    \n",
    "    # 5. Visualize\n",
    "    fig = plot_results(ticker, signals_df)\n",
    "    \n",
    "    return signals_df, metrics, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing AAPL from 2023-01-01 to 2023-12-31\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "Not allowed to merge between different levels. (2 levels on the left, 1 on the right)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     signals, metrics, fig \u001b[38;5;241m=\u001b[39m run_analysis(\n\u001b[1;32m      4\u001b[0m         ticker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m         start_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         end_date\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-12-31\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m         threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPerformance Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[31], line 16\u001b[0m, in \u001b[0;36mrun_analysis\u001b[0;34m(ticker, start_date, end_date, threshold)\u001b[0m\n\u001b[1;32m     13\u001b[0m sentiment_scores \u001b[38;5;241m=\u001b[39m analyze_sentiment(news_data)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 3. Generate signals\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m signals_df \u001b[38;5;241m=\u001b[39m generate_signals(stock_data, sentiment_scores, threshold)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 4. Backtest\u001b[39;00m\n\u001b[1;32m     19\u001b[0m metrics \u001b[38;5;241m=\u001b[39m backtest_strategy(signals_df)\n",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m, in \u001b[0;36mgenerate_signals\u001b[0;34m(stock_df, sentiment_df, threshold, use_rolling)\u001b[0m\n\u001b[1;32m     20\u001b[0m     sentiment_data \u001b[38;5;241m=\u001b[39m sentiment_data\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Merge data using join (more robust for index merging)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m merged \u001b[38;5;241m=\u001b[39m stock_data\u001b[38;5;241m.\u001b[39mjoin(sentiment_data, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Forward fill sentiment scores\u001b[39;00m\n\u001b[1;32m     26\u001b[0m sentiment_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     27\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_compound\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10757\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m  10747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  10748\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m  10749\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10750\u001b[0m             other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10755\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m  10756\u001b[0m         )\n\u001b[0;32m> 10757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m  10758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10759\u001b[0m         other,\n\u001b[1;32m  10760\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m  10761\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m  10762\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mon \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10763\u001b[0m         right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m  10764\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39m(lsuffix, rsuffix),\n\u001b[1;32m  10765\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m  10766\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m  10767\u001b[0m     )\n\u001b[1;32m  10768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m  10769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    156\u001b[0m         left_df,\n\u001b[1;32m    157\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[1;32m    173\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m    174\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m    175\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m    176\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m    177\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m    178\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m    179\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    180\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m    181\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:784\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _left\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m!=\u001b[39m _right\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[1;32m    779\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot allowed to merge between different levels. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_left\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m levels on the left, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_right\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on the right)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    783\u001b[0m     )\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_on, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_left_right_on(left_on, right_on)\n\u001b[1;32m    788\u001b[0m (\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m     right_drop,\n\u001b[1;32m    794\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n",
      "\u001b[0;31mMergeError\u001b[0m: Not allowed to merge between different levels. (2 levels on the left, 1 on the right)"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    signals, metrics, fig = run_analysis(\n",
    "        ticker=\"AAPL\",\n",
    "        start_date=\"2023-01-01\",\n",
    "        end_date=\"2023-12-31\",\n",
    "        threshold=0.2\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:>20}: {v:.4f}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
